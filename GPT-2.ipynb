{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNeYXggTuBKoBufGcYOIniy",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mojito9542/gpt-2/blob/master/GPT-2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v68PP_sjLdr9",
        "colab_type": "text"
      },
      "source": [
        "Initializing the notebook\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2lG0hTK0Lkxr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "c58b0cb7-89f7-4343-af45-2809b45e8645"
      },
      "source": [
        "!git clone https://github.com/openai/gpt-2 "
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'gpt-2'...\n",
            "remote: Enumerating objects: 230, done.\u001b[K\n",
            "remote: Total 230 (delta 0), reused 0 (delta 0), pack-reused 230\u001b[K\n",
            "Receiving objects: 100% (230/230), 4.38 MiB | 6.68 MiB/s, done.\n",
            "Resolving deltas: 100% (121/121), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U4Xwh72mLp52",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "034daaae-0b45-4185-bf91-a53795473f51"
      },
      "source": [
        "ls"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[0m\u001b[01;34mgpt-2\u001b[0m/  \u001b[01;34msample_data\u001b[0m/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zt5HuN9PMER8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "732f0c49-bbb6-40e2-caa7-d86e2da8ec7a"
      },
      "source": [
        "cd gpt-2"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gpt-2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ySFx2FL-MMl6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 668
        },
        "outputId": "bf51f55b-918b-4d19-cd2c-8abe62207c8c"
      },
      "source": [
        "!pip install -r requirements.txt"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting fire>=0.1.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d9/69/faeaae8687f4de0f5973694d02e9d6c3eb827636a009157352d98de1129e/fire-0.2.1.tar.gz (76kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 6.1MB/s \n",
            "\u001b[?25hCollecting regex==2017.4.5\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/36/62/c0c0d762ffd4ffaf39f372eb8561b8d491a11ace5a7884610424a8b40f95/regex-2017.04.05.tar.gz (601kB)\n",
            "\u001b[K     |████████████████████████████████| 604kB 26.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests==2.21.0 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 3)) (2.21.0)\n",
            "Collecting tqdm==4.31.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/6c/4b/c38b5144cf167c4f52288517436ccafefe9dc01b8d1c190e18a6b154cd4a/tqdm-4.31.1-py2.py3-none-any.whl (48kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 8.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from fire>=0.1.3->-r requirements.txt (line 1)) (1.12.0)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.6/dist-packages (from fire>=0.1.3->-r requirements.txt (line 1)) (1.1.0)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests==2.21.0->-r requirements.txt (line 3)) (1.24.3)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests==2.21.0->-r requirements.txt (line 3)) (2.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests==2.21.0->-r requirements.txt (line 3)) (2019.11.28)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests==2.21.0->-r requirements.txt (line 3)) (3.0.4)\n",
            "Building wheels for collected packages: fire, regex\n",
            "  Building wheel for fire (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fire: filename=fire-0.2.1-py2.py3-none-any.whl size=103528 sha256=b7dc771b5fcaf60a108edf848d41c7b00f4fec3b52e71694d3149086596725aa\n",
            "  Stored in directory: /root/.cache/pip/wheels/31/9c/c0/07b6dc7faf1844bb4688f46b569efe6cafaa2179c95db821da\n",
            "  Building wheel for regex (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for regex: filename=regex-2017.4.5-cp36-cp36m-linux_x86_64.whl size=533184 sha256=c5e0f39695b3978979c1a842e58822ea71bcd3771585200333445b448e42be96\n",
            "  Stored in directory: /root/.cache/pip/wheels/75/07/38/3c16b529d50cb4e0cd3dbc7b75cece8a09c132692c74450b01\n",
            "Successfully built fire regex\n",
            "Installing collected packages: fire, regex, tqdm\n",
            "  Found existing installation: regex 2019.12.20\n",
            "    Uninstalling regex-2019.12.20:\n",
            "      Successfully uninstalled regex-2019.12.20\n",
            "  Found existing installation: tqdm 4.28.1\n",
            "    Uninstalling tqdm-4.28.1:\n",
            "      Successfully uninstalled tqdm-4.28.1\n",
            "Successfully installed fire-0.2.1 regex-2017.4.5 tqdm-4.31.1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "tqdm"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cPOpyYFCMRXa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "f0cd01bd-d72d-4487-94ac-c6d96e404289"
      },
      "source": [
        "cat DEVELOPERS.md"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "# Installation\n",
            "\n",
            "Git clone this repository, and `cd` into directory for remaining commands\n",
            "```\n",
            "git clone https://github.com/openai/gpt-2.git && cd gpt-2\n",
            "```\n",
            "\n",
            "Then, follow instructions for either native or Docker installation.\n",
            "\n",
            "## Native Installation\n",
            "\n",
            "All steps can optionally be done in a virtual environment using tools such as `virtualenv` or `conda`.\n",
            "\n",
            "Install tensorflow 1.12 (with GPU support, if you have a GPU and want everything to run faster)\n",
            "```\n",
            "pip3 install tensorflow==1.12.0\n",
            "```\n",
            "or\n",
            "```\n",
            "pip3 install tensorflow-gpu==1.12.0\n",
            "```\n",
            "\n",
            "Install other python packages:\n",
            "```\n",
            "pip3 install -r requirements.txt\n",
            "```\n",
            "\n",
            "Download the model data\n",
            "```\n",
            "python3 download_model.py 124M\n",
            "python3 download_model.py 355M\n",
            "python3 download_model.py 774M\n",
            "python3 download_model.py 1558M\n",
            "```\n",
            "\n",
            "## Docker Installation\n",
            "\n",
            "Build the Dockerfile and tag the created image as `gpt-2`:\n",
            "```\n",
            "docker build --tag gpt-2 -f Dockerfile.gpu . # or Dockerfile.cpu\n",
            "```\n",
            "\n",
            "Start an interactive bash session from the `gpt-2` docker image.\n",
            "\n",
            "You can opt to use the `--runtime=nvidia` flag if you have access to a NVIDIA GPU\n",
            "and a valid install of [nvidia-docker 2.0](https://github.com/nvidia/nvidia-docker/wiki/Installation-(version-2.0)).\n",
            "```\n",
            "docker run --runtime=nvidia -it gpt-2 bash\n",
            "```\n",
            "\n",
            "# Running\n",
            "\n",
            "| WARNING: Samples are unfiltered and may contain offensive content. |\n",
            "| --- |\n",
            "\n",
            "Some of the examples below may include Unicode text characters. Set the environment variable:\n",
            "```\n",
            "export PYTHONIOENCODING=UTF-8\n",
            "```\n",
            "to override the standard stream settings in UTF-8 mode.\n",
            "\n",
            "## Unconditional sample generation\n",
            "\n",
            "To generate unconditional samples from the small model:\n",
            "```\n",
            "python3 src/generate_unconditional_samples.py | tee /tmp/samples\n",
            "```\n",
            "There are various flags for controlling the samples:\n",
            "```\n",
            "python3 src/generate_unconditional_samples.py --top_k 40 --temperature 0.7 | tee /tmp/samples\n",
            "```\n",
            "\n",
            "To check flag descriptions, use:\n",
            "```\n",
            "python3 src/generate_unconditional_samples.py -- --help\n",
            "```\n",
            "\n",
            "## Conditional sample generation\n",
            "\n",
            "To give the model custom prompts, you can use:\n",
            "```\n",
            "python3 src/interactive_conditional_samples.py --top_k 40\n",
            "```\n",
            "\n",
            "To check flag descriptions, use:\n",
            "```\n",
            "python3 src/interactive_conditional_samples.py -- --help\n",
            "```\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jo8xEZ8BMZLB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 510
        },
        "outputId": "ce2d59ee-0a8d-47bd-f552-7bc84c885d8d"
      },
      "source": [
        "!python3 download_model.py 124M\n",
        "!python3 download_model.py 355M\n",
        "!python3 download_model.py 774M\n",
        "!python3 download_model.py 1558M"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\rFetching checkpoint:   0%|                                              | 0.00/77.0 [00:00<?, ?it/s]\rFetching checkpoint: 1.00kit [00:00, 1.30Mit/s]                                                     \n",
            "\rFetching encoder.json:   0%|                                           | 0.00/1.04M [00:00<?, ?it/s]\rFetching encoder.json: 1.04Mit [00:00, 52.0Mit/s]                                                   \n",
            "Fetching hparams.json: 1.00kit [00:00, 1.29Mit/s]                                                   \n",
            "Fetching model.ckpt.data-00000-of-00001: 498Mit [00:05, 88.7Mit/s]                                  \n",
            "Fetching model.ckpt.index: 6.00kit [00:00, 5.92Mit/s]                                               \n",
            "Fetching model.ckpt.meta: 472kit [00:00, 54.6Mit/s]                                                 \n",
            "Fetching vocab.bpe: 457kit [00:00, 51.7Mit/s]                                                       \n",
            "Fetching checkpoint: 1.00kit [00:00, 1.06Mit/s]                                                     \n",
            "Fetching encoder.json: 1.04Mit [00:00, 55.9Mit/s]                                                   \n",
            "Fetching hparams.json: 1.00kit [00:00, 1.21Mit/s]                                                   \n",
            "Fetching model.ckpt.data-00000-of-00001: 1.42Git [00:25, 55.1Mit/s]                                 \n",
            "Fetching model.ckpt.index: 11.0kit [00:00, 8.88Mit/s]                                               \n",
            "Fetching model.ckpt.meta: 927kit [00:00, 54.7Mit/s]                                                 \n",
            "Fetching vocab.bpe: 457kit [00:00, 41.3Mit/s]                                                       \n",
            "Fetching checkpoint: 1.00kit [00:00, 1.25Mit/s]                                                     \n",
            "Fetching encoder.json: 1.04Mit [00:00, 70.7Mit/s]                                                   \n",
            "Fetching hparams.json: 1.00kit [00:00, 1.17Mit/s]                                                   \n",
            "Fetching model.ckpt.data-00000-of-00001: 3.10Git [00:55, 55.6Mit/s]                                 \n",
            "Fetching model.ckpt.index: 16.0kit [00:00, 10.2Mit/s]                                               \n",
            "Fetching model.ckpt.meta: 1.38Mit [00:00, 72.9Mit/s]                                                \n",
            "Fetching vocab.bpe: 457kit [00:00, 66.3Mit/s]                                                       \n",
            "Fetching checkpoint: 1.00kit [00:00, 1.10Mit/s]                                                     \n",
            "Fetching encoder.json: 1.04Mit [00:00, 50.8Mit/s]                                                   \n",
            "Fetching hparams.json: 1.00kit [00:00, 1.12Mit/s]                                                   \n",
            "Fetching model.ckpt.data-00000-of-00001: 6.23Git [02:34, 40.3Mit/s]                                 \n",
            "Fetching model.ckpt.index: 21.0kit [00:00, 16.6Mit/s]                                               \n",
            "Fetching model.ckpt.meta: 1.84Mit [00:00, 63.3Mit/s]                                                \n",
            "Fetching vocab.bpe: 457kit [00:00, 51.3Mit/s]                                                       \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tIR6rCa4Mr_n",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "8f874010-519f-4b95-f456-0d2e4da96214"
      },
      "source": [
        "ls\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CONTRIBUTORS.md  Dockerfile.gpu     LICENSE        README.md\n",
            "DEVELOPERS.md    domains.txt        model_card.md  requirements.txt\n",
            "Dockerfile.cpu   download_model.py  \u001b[0m\u001b[01;34mmodels\u001b[0m/        \u001b[01;34msrc\u001b[0m/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bQVvJxvyQqPy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "dc0d3a02-8608-453c-d723-e6863344ba03"
      },
      "source": [
        "!python3 src/interactive_conditional_samples.py --model_name \"1558M\""
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From src/interactive_conditional_samples.py:57: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "2020-02-20 06:23:00.270201: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
            "2020-02-20 06:23:00.317708: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-02-20 06:23:00.318384: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n",
            "name: Tesla P4 major: 6 minor: 1 memoryClockRate(GHz): 1.1135\n",
            "pciBusID: 0000:00:04.0\n",
            "2020-02-20 06:23:00.340701: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-02-20 06:23:00.564943: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2020-02-20 06:23:00.706383: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
            "2020-02-20 06:23:00.734796: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
            "2020-02-20 06:23:01.000686: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
            "2020-02-20 06:23:01.026099: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
            "2020-02-20 06:23:01.523050: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-02-20 06:23:01.523266: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-02-20 06:23:01.523917: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-02-20 06:23:01.526537: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n",
            "2020-02-20 06:23:01.527124: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX512F\n",
            "2020-02-20 06:23:01.536515: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2000165000 Hz\n",
            "2020-02-20 06:23:01.537857: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x23df640 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
            "2020-02-20 06:23:01.537895: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
            "2020-02-20 06:23:01.729338: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-02-20 06:23:01.730118: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x23dfd40 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
            "2020-02-20 06:23:01.730168: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla P4, Compute Capability 6.1\n",
            "2020-02-20 06:23:01.731131: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-02-20 06:23:01.731514: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n",
            "name: Tesla P4 major: 6 minor: 1 memoryClockRate(GHz): 1.1135\n",
            "pciBusID: 0000:00:04.0\n",
            "2020-02-20 06:23:01.731596: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-02-20 06:23:01.731623: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2020-02-20 06:23:01.731642: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
            "2020-02-20 06:23:01.731662: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
            "2020-02-20 06:23:01.731818: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
            "2020-02-20 06:23:01.731874: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
            "2020-02-20 06:23:01.731921: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-02-20 06:23:01.732078: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-02-20 06:23:01.732717: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-02-20 06:23:01.733083: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n",
            "2020-02-20 06:23:01.735633: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-02-20 06:23:01.736760: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2020-02-20 06:23:01.736793: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 \n",
            "2020-02-20 06:23:01.736807: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N \n",
            "2020-02-20 06:23:01.737959: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-02-20 06:23:01.738450: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-02-20 06:23:01.738822: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2020-02-20 06:23:01.738863: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 7123 MB memory) -> physical GPU (device: 0, name: Tesla P4, pci bus id: 0000:00:04.0, compute capability: 6.1)\n",
            "WARNING:tensorflow:From src/interactive_conditional_samples.py:58: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From src/interactive_conditional_samples.py:60: The name tf.set_random_seed is deprecated. Please use tf.compat.v1.set_random_seed instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/gpt-2/src/sample.py:51: The name tf.AUTO_REUSE is deprecated. Please use tf.compat.v1.AUTO_REUSE instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/gpt-2/src/model.py:148: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/gpt-2/src/model.py:152: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/gpt-2/src/model.py:36: The name tf.rsqrt is deprecated. Please use tf.math.rsqrt instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/gpt-2/src/sample.py:64: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "WARNING:tensorflow:From /content/gpt-2/src/sample.py:39: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /content/gpt-2/src/sample.py:67: multinomial (from tensorflow.python.ops.random_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.random.categorical` instead.\n",
            "WARNING:tensorflow:From src/interactive_conditional_samples.py:68: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n",
            "\n",
            "Hi! My name is Mohit Agarwal. I love eating desserts. \n",
            "Model prompt >>> 2020-02-20 06:26:19.798124: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "I dont know What to do with my life anymore. So i decided to become a rockstar. For that I quit my job as it was neccesary to dedicate my undivided attention to it. After that I practiced every day. But i never succeded throwing rocks to star however hard i try.\n",
            "======================================== SAMPLE 1 ========================================\n",
            " Hundreds of my genetics administer variants called duration polymorphisms in the gene encoding the sweet taste receptor, known as T1R2. Each of the polymorphisms, R128A and R151T, while thought to affect whether a person likes, or not likes, sweets, can be subdivided into five different categories: Sweet taste liking Traumatic taste liking Sweetness Acceptance Sweetness aversion Flavour perception Traumatic (stinging, burning), balmy and salivating taste dysphoria Sweetness appetite Predator-prey stress reproductive One elusive panelist was transfixed by a type of eating disorder displayed by a deformed pit bull puppy she rescued. This disorder displays an extreme fear of teat, and as the dog (grown male, at the time) became overweight it developed a chronic and painless skin injury and severe vulval dermatomyositis. This was truly bizarre: painful, itchy, nightmarish.(12) Approaching a drinking fountain saw a youngster having an aggressive attack against his mother and female companion. She remembered that the youngster had sought protection from something in a commune two days earlier. Closer examination revealed that the youngster, after achieving a space boundary, banged the door of the toilet with chicken bones relished his favourite Frisbee. Even the cheerful endlessly imaging Plaseau expects to see here now.\n",
            "Too much sweets can induce similar bowel upsets.  Marvellous moment with the pool, maybe a joint? Bake well, chill, stay normal.\n",
            "D Still fat, though.\n",
            "One striking thing about the panel of the German study, their normal appearance had been either scarring or not so normal, because his wrist lacked the usual tricep growth. It was just a parallel in evolution to the case of disease.  Clearly this person was different.  Then this person had served with Germany in Morocco in January-March 1989 thanks to an award call with long lead time.     Even his foreign experience, whilst acquired some week later than had thought, was a success, his wife understood. He became part of a cadre of young cooks in several black families. After a telephone conversation with the mother, the husband requested that we not contact him. On the contrary, we should communicate with us are we loved him.\n",
            "Most curiously, he could see all, but he had a very prominent left eye, as did many members of his family. He was slowed by highway speed direction but not by emergency vehicles.\n",
            "Rightward.\n",
            "There was\n",
            "================================================================================\n",
            "Model prompt >>> hi\n",
            "======================================== SAMPLE 1 ========================================\n",
            " I got my hate and start burning my fingers from throwing. It was not even enough it was too much trouble. later I discovered how to run like acow.I had a brief goal to be like simon paul soundman. (helped him a lot in his career) I dont know what to do with my life anymore. So i decided to become a rockstar. For that I quit my job as it was neccesary to dedicate my undivided attention to it. After that I practiced every day.But i never succeded throwing rocks to star however hard i try. I got my hate and start burning my fingers from throwing. It was not even enough it was too much trouble. later\n",
            "\n",
            "Music and performers: Pariah X × Dark Comet — \"Hook\" ( _uic3 ) × Scott Molinakis × Marilyn Manson × Max Styler × Guilty Simpson × Jeff Garnett × FantastiC × Josh Myers × A$AP Rocky\n",
            "\n",
            "――\n",
            "\n",
            "Ani Mitsuji, Hell's Angel To do this screen capturing thing, you have to follow from left to right… That's pretty hard to do with only one of your fingers!! In fact, I can only do it when I'm convinced I never need to use my other finger like this. ugh.\n",
            "\n",
            "Music and performers: Eddie Montgomery × Aurephan — \"Dash\" ( c_vsp ) × ONS (@syqbookdaddy) × Carrick Shields × Lady Chablis × LaSkar × Kaytranada\n",
            "\n",
            "――\n",
            "\n",
            "God, less hand movements… Save your wishful thinking for when you're 7 inches tall.\n",
            "\n",
            "Music and performers: The Fugees × Lisa Loeb\n",
            "\n",
            "――\n",
            "\n",
            "[Sleepwalking in the Presidential Affairs Zone]\n",
            "\n",
            "Note that things definitely are not as bad as they seem right before an emergency! Haha. Thanks my savior Peter Van Houten for accompanying me in these studies. Will smugly gloat to plot points they concealed from discussions in Teankara.\n",
            "\n",
            "Music and performers: Stephen Lang × Itagaki Makoto L.M. × Rising Force × Serena Fuji ( Remi ), Michikazu Kusano × Hiroyoshi Tenzan × Vince-kun ×<|endoftext|>Are you concerned about when your local pothole will become a highway? This is a vehicle pothole that worries many residents, as it proved fatal for a child four years ago, and\n",
            "================================================================================\n",
            "Model prompt >>> ======================================== SAMPLE 1 ========================================\n",
            ", Aru Akamno, Naohisa Ohata, Eiichiro Sasano, Masahiko Date, Takeharu Gotou, Riki Iwai, Koji Igarashi, Noshiro Tano, Tomooaki Inoue, Takaaki Kuroda, Hiroko Fujimori, Hiroko Watachi, Baka Shin, Kazuya Ogawa, Saburo cover illustrations Kenshito Sugawara Uilin Pang, the first human captured by Whisper is arrested by Whisper, and sent to the Therian Research Facility where he was implanted with a Onyx Core core within his heart that he can now program his Servant with.[11]\n",
            "\n",
            "Unbeknownst to him, this Onyx Core has been given to the Impure King by the Will of the Velvet Darkling, who wishes to somehow magnify the power of his minions. The Impure King reaches out to Plant, who petrifies most of the humans and CET was \"killed\", unable to produce Resources, vehicles enough to abduct more men, or sufficient size and material to support more men. The Man Who Became Zheng He observes the destruction of the people of the gas station, discovers who all of the impurities are, and escapes before he can act. This is going to be the catalyst to the curse of the Crown in Christian theology. With the armor lining and guts of Valentinian 4 removed, and the human heart exposed, Zheng He's side is blown open and he now has access to whatever the main body can grasp and control.\n",
            "\n",
            "Going through the supply lines of the executiveia of the continent, Zheng He arrives in the slums of Prague, observing the chaos. He is confronted and stopped by Géza, the bodyguard of Łukas Seniö. Géza and the Impure King are told by Santana and Hämsterviel to surrender, as they cannot fight their way out of a Salvatore vinifera net covered cardboard box while Big Mugga copulates with her. But their plan to make a show of victory and capture a bunch of people for worth of their St. Andrew's Cross has been busted due to Kazuma, Paris, and Guella joining the battle, and the attack directly causes an earthquake which wipes out the entire street below. Zheng He infiltrates Seniostra's Tower Module Maktabi, destroys its central basis, and emerging, is confronted by Suzaku Kururugi R\n",
            "================================================================================\n",
            "Model prompt >>> Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.6/contextlib.py\", line 99, in __exit__\n",
            "    self.gen.throw(type, value, traceback)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py\", line 5480, in get_controller\n",
            "    yield g\n",
            "  File \"src/interactive_conditional_samples.py\", line 73, in interact_model\n",
            "    raw_text = input(\"Model prompt >>> \")\n",
            "KeyboardInterrupt\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"src/interactive_conditional_samples.py\", line 91, in <module>\n",
            "    fire.Fire(interact_model)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/fire/core.py\", line 138, in Fire\n",
            "    component_trace = _Fire(component, args, parsed_flag_args, context, name)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/fire/core.py\", line 471, in _Fire\n",
            "    target=component.__name__)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/fire/core.py\", line 675, in _CallAndUpdateTrace\n",
            "    component = fn(*varargs, **kwargs)\n",
            "  File \"src/interactive_conditional_samples.py\", line 88, in interact_model\n",
            "    print(\"=\" * 80)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\", line 1633, in __exit__\n",
            "    close_thread.start()\n",
            "  File \"/usr/lib/python3.6/threading.py\", line 851, in start\n",
            "    self._started.wait()\n",
            "  File \"/usr/lib/python3.6/threading.py\", line 551, in wait\n",
            "    signaled = self._cond.wait(timeout)\n",
            "  File \"/usr/lib/python3.6/threading.py\", line 295, in wait\n",
            "    waiter.acquire()\n",
            "KeyboardInterrupt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h01XR6Z8Q2CG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 406
        },
        "outputId": "d37d6870-910c-4d33-897e-b39f16295edf"
      },
      "source": [
        "!python3 src/interactive_conditional_samples.py --help"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO: Showing help with the command 'interactive_conditional_samples.py -- --help'.\n",
            "\n",
            "\u001b[1mNAME\u001b[0m\n",
            "    interactive_conditional_samples.py - Interactively run the model :model_name=124M : String, which model to use :seed=None : Integer seed for random number generators, fix seed to reproduce results :nsamples=1 : Number of samples to return total :batch_size=1 : Number of batches (only affects speed/memory).  Must divide nsamples. :length=None : Number of tokens in generated text, if None (default), is determined by model hyperparameters :temperature=1 : Float value controlling randomness in boltzmann distribution. Lower temperature results in less random completions. As the temperature approaches zero, the model will become deterministic and repetitive. Higher temperature results in more random completions. :top_k=0 : Integer value controlling diversity. 1 means only 1 word is considered for each step (token), resulting in deterministic completions, while 40 means 40 words are considered at each step. 0 (default) is a special setting meaning no restrictions. 40 generally is a good value. :models_dir : path to parent folder containing model subfolders (i.e. contains the <model_name> folder)\n",
            "\n",
            "\u001b[1mSYNOPSIS\u001b[0m\n",
            "    interactive_conditional_samples.py <flags>\n",
            "\n",
            "\u001b[1mDESCRIPTION\u001b[0m\n",
            "    Interactively run the model :model_name=124M : String, which model to use :seed=None : Integer seed for random number generators, fix seed to reproduce results :nsamples=1 : Number of samples to return total :batch_size=1 : Number of batches (only affects speed/memory).  Must divide nsamples. :length=None : Number of tokens in generated text, if None (default), is determined by model hyperparameters :temperature=1 : Float value controlling randomness in boltzmann distribution. Lower temperature results in less random completions. As the temperature approaches zero, the model will become deterministic and repetitive. Higher temperature results in more random completions. :top_k=0 : Integer value controlling diversity. 1 means only 1 word is considered for each step (token), resulting in deterministic completions, while 40 means 40 words are considered at each step. 0 (default) is a special setting meaning no restrictions. 40 generally is a good value. :models_dir : path to parent folder containing model subfolders (i.e. contains the <model_name> folder)\n",
            "\n",
            "\u001b[1mFLAGS\u001b[0m\n",
            "    --model_name=\u001b[4mMODEL_NAME\u001b[0m\n",
            "    --seed=\u001b[4mSEED\u001b[0m\n",
            "    --nsamples=\u001b[4mNSAMPLES\u001b[0m\n",
            "    --batch_size=\u001b[4mBATCH_SIZE\u001b[0m\n",
            "    --length=\u001b[4mLENGTH\u001b[0m\n",
            "    --temperature=\u001b[4mTEMPERATURE\u001b[0m\n",
            "    --top_k=\u001b[4mTOP_K\u001b[0m\n",
            "    --top_p=\u001b[4mTOP_P\u001b[0m\n",
            "    --models_dir=\u001b[4mMODELS_DIR\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vkNxDM8yT7Cl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "c52ac6f1-75a2-4462-807f-5ab6ebbe4136"
      },
      "source": [
        "!python3 src/interactive_conditional_samples.py --model_name \"774M\" --nsamples=15 --length=50\n"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From src/interactive_conditional_samples.py:57: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "2020-02-20 09:02:46.291928: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
            "2020-02-20 09:02:46.313434: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-02-20 09:02:46.313825: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n",
            "name: Tesla P4 major: 6 minor: 1 memoryClockRate(GHz): 1.1135\n",
            "pciBusID: 0000:00:04.0\n",
            "2020-02-20 09:02:46.314133: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-02-20 09:02:46.315746: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2020-02-20 09:02:46.317338: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
            "2020-02-20 09:02:46.317665: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
            "2020-02-20 09:02:46.319148: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
            "2020-02-20 09:02:46.320686: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
            "2020-02-20 09:02:46.323862: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-02-20 09:02:46.323995: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-02-20 09:02:46.324411: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-02-20 09:02:46.324760: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n",
            "2020-02-20 09:02:46.325132: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX512F\n",
            "2020-02-20 09:02:46.329525: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2000165000 Hz\n",
            "2020-02-20 09:02:46.329737: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x3247100 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
            "2020-02-20 09:02:46.329784: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
            "2020-02-20 09:02:46.409155: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-02-20 09:02:46.409719: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x32472c0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
            "2020-02-20 09:02:46.409752: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla P4, Compute Capability 6.1\n",
            "2020-02-20 09:02:46.409938: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-02-20 09:02:46.410349: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n",
            "name: Tesla P4 major: 6 minor: 1 memoryClockRate(GHz): 1.1135\n",
            "pciBusID: 0000:00:04.0\n",
            "2020-02-20 09:02:46.410442: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-02-20 09:02:46.410473: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2020-02-20 09:02:46.410500: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
            "2020-02-20 09:02:46.410530: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
            "2020-02-20 09:02:46.410552: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
            "2020-02-20 09:02:46.410580: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
            "2020-02-20 09:02:46.410609: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-02-20 09:02:46.410691: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-02-20 09:02:46.411149: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-02-20 09:02:46.411516: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n",
            "2020-02-20 09:02:46.411604: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-02-20 09:02:46.412741: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2020-02-20 09:02:46.412770: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 \n",
            "2020-02-20 09:02:46.412782: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N \n",
            "2020-02-20 09:02:46.412892: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-02-20 09:02:46.413351: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-02-20 09:02:46.413743: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2020-02-20 09:02:46.413788: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 7123 MB memory) -> physical GPU (device: 0, name: Tesla P4, pci bus id: 0000:00:04.0, compute capability: 6.1)\n",
            "WARNING:tensorflow:From src/interactive_conditional_samples.py:58: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From src/interactive_conditional_samples.py:60: The name tf.set_random_seed is deprecated. Please use tf.compat.v1.set_random_seed instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/gpt-2/src/sample.py:51: The name tf.AUTO_REUSE is deprecated. Please use tf.compat.v1.AUTO_REUSE instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/gpt-2/src/model.py:148: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/gpt-2/src/model.py:152: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/gpt-2/src/model.py:36: The name tf.rsqrt is deprecated. Please use tf.math.rsqrt instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/gpt-2/src/sample.py:64: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "WARNING:tensorflow:From /content/gpt-2/src/sample.py:39: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /content/gpt-2/src/sample.py:67: multinomial (from tensorflow.python.ops.random_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.random.categorical` instead.\n",
            "WARNING:tensorflow:From src/interactive_conditional_samples.py:68: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n",
            "\n",
            "Model prompt >>> There once was a speedy Hare who bragged about how fast he could run. Tired of hearing him boast, the Tortoise challenged him to a race. All the animals in the forest gathered to watch.  The Hare ran down the road for a while and then paused to rest. He looked back at the tortoise and cried out, \"How do you expect to win this race when you are walking along at your slow, slow pace?\"  The Hare stretched himself out alongside the road and fell asleep, thinking, \"There is plenty of time to relax.\" The Tortoise walked and walked, never ever stopping until he came to the finish line.  The animals who were watching cheered so loudly for Tortoise that they woke up the Hare. The Hare stretched, yawned and began to run again, but it was too late. Tortoise had already crossed the finish line. TL;DR\n",
            "2020-02-20 09:04:07.516815: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "======================================== SAMPLE 1 ========================================\n",
            ": Hare claims he can cry out, \"How are you supposed to run when you are full of energy?\"\n",
            "\n",
            "Saving the Dragon -> Q&A -> Summary\n",
            "\n",
            "WorkshopActivity -> Restage\n",
            "\n",
            "Build Crawl 1.8\n",
            "======================================== SAMPLE 2 ========================================\n",
            "!  I bet Tortoise would beat the Hare at that race!<|endoftext|>A husband and wife who were sitting on their sofa in a hotel in the United Arab Emirates pounced on a leopard two and a half years ago before it attacked them.\n",
            "======================================== SAMPLE 3 ========================================\n",
            " This word is pretty non-functional in Super Mario World. the epitomizes the stream of thought that can occur at the mere sight of anything (by having the verb with no modifier, for example.) as if... x-y phonetically recognized\n",
            "======================================== SAMPLE 4 ========================================\n",
            ": All the animals are tired of amusing the turtle while he runs around the forest. Tortoise cried and ran into the jaws of the tortoise. Hare replied sarcastically saying, \"It is the tortoise who is slow!\" (for those who\n",
            "======================================== SAMPLE 5 ========================================\n",
            ": An adult alligator shall set his slow running speed to the max and finish in a few seconds. Also, female tortoises have the same official berry harvest as male tortoises. Compound sentences have complicated meanings. In China,\n",
            "======================================== SAMPLE 6 ========================================\n",
            ": In fairytales, the slow, slow train wins the race.\n",
            "\n",
            "A Short Update (2014-7-27)\n",
            "\n",
            "I realized that mentioning the Kamisato Faction of Glory – a faction that seems to involve a new,\n",
            "======================================== SAMPLE 7 ========================================\n",
            ": You couldn't turn on the time limiter on bad devices.\n",
            "\n",
            "Now let me ask a question: Why does this happen on the PS Vita?\n",
            "\n",
            "But as for the pinball, when on the wrong panel, the ball can\n",
            "======================================== SAMPLE 8 ========================================\n",
            " - Hare came out faster than tortoise and thus won. To sum up: Tortoise ran to win and Hare got upset that he couldn't win.\n",
            "\n",
            "Grew up eating chewy cereal banana with jelly spawning inside her mouth Eggsprites\n",
            "======================================== SAMPLE 9 ========================================\n",
            " - Hare challenged tortoise to race and tortoise ran down road for insec.<|endoftext|>Defensive lineman Zach Banner is averaging 15 tackles per game during preseason - second best in the NFL. (Photo: Jerry Lai, USA TODAY Sports)\n",
            "\n",
            "======================================== SAMPLE 10 ========================================\n",
            ": Hare was too fast for the Tortoise, he had to slow down to run down the road.<|endoftext|>One Night Stand\n",
            "\n",
            "Eran Kadlec plays a go-getter with the Invisible Cavaliers, wakes up crying at his understudy\n",
            "======================================== SAMPLE 11 ========================================\n",
            ": • country dog stopped at fairy realm. • hind walks into fairy realm • massive consort activates secret of infinity • elephant and deer jump on tortoise\n",
            "\n",
            "RAW Paste Data\n",
            "\n",
            "TPDDelta Scala by cserrano http://stepan\n",
            "======================================== SAMPLE 12 ========================================\n",
            " http://imgur.com/a/9mHmn<|endoftext|>CREDIT: Everett Collection\n",
            "\n",
            "We first met Brad Bush on his cabaret shoe tour in the mid-'90s. Back then, he was not the polished soul that he is\n",
            "======================================== SAMPLE 13 ========================================\n",
            " Because it is possible to create a game in 3D without really touching the hardware.\n",
            "\n",
            "Episode 11 (??? - 60% unlocked)\n",
            "\n",
            "The next episode was not revealed until 5 years later. The narration didn't explain the Gordian knot\n",
            "======================================== SAMPLE 14 ========================================\n",
            ": Motor madness, Lane the intent cause break in time, getting first in the race because the rest weren't there.\n",
            "\n",
            "Page 7 Edit\n",
            "\n",
            "The Ace Combat 5th Generation (AC5G) is a turn-based, free-\n",
            "======================================== SAMPLE 15 ========================================\n",
            ": This reminds me that vegetarians (and others) are sometimes called gullible and fall for propaganda hype . They also get their opinions and goals from friends, without thinking. Confusing ? Consider this…This makes a much more descriptive recap: A\n",
            "================================================================================\n",
            "Model prompt >>> The Tortoise walked and walked, never ever stopping until he came to the finish line.  The animals who were watching cheered so loudly for Tortoise that they woke up the Hare. The Hare stretched, yawned and began to run again, but it was too late. Tortoise had already crossed the finish line. So in conclusion \n",
            "======================================== SAMPLE 1 ========================================\n",
            "  the Tortoise won.<|endoftext|>The Seventh Third Special Lecture\n",
            "\n",
            "\n",
            "Marcelo Mamenhofer\n",
            "\n",
            "UNIVERSITY OF AUSTRIA\n",
            "\n",
            "Centre for European Economic Research (CEER)\n",
            "\n",
            "Reforming the heavily\n",
            "======================================== SAMPLE 2 ========================================\n",
            " Tortoise was the winner. He made the winning song with his definition of as well as his beauty all flawless. It was impossible for him to miss THE lead. The Hare paid no attention to any present and simply led the final 30!\n",
            "======================================== SAMPLE 3 ========================================\n",
            " - beware the \"too much respect\" Tortoise.\n",
            "The Convoy (fact or fiction)\n",
            "Susie and Sara, just off school days, sit in the back of their car. In the evening, as busy as they both are\n",
            "======================================== SAMPLE 4 ========================================\n",
            "  The Tortoise was a winner, Tomorrow Sickness will be a home run for all of the animals shown. It is a very simple exercise, the previous series of pictures clearly show how.\n",
            "The Tortoise hit the finish line with\n",
            "======================================== SAMPLE 5 ========================================\n",
            " this is thought experiment of flowering plant euphoria MiaSoon Shares: When the helpful British scientists Jane Where and John Hicks called a scientific conference on sunny garden plants and introduced them to the conference clerk. \"...hence time flew past and the conference was in\n",
            "======================================== SAMPLE 6 ========================================\n",
            ": New Zealand, if you are raising animals this will be your bugaboo.<|endoftext|>For architects, the concept of a 'built environment' was crystallised in a famous lecture by Peter Saville which focussed on the concepts of 'form'\n",
            "======================================== SAMPLE 7 ========================================\n",
            "\n",
            "Left: The investigation The next major investigation of that night was carried out by the local public advocate Felix van Leeuwenhoek.  In the past, such cases of alleged journalistic journalism were investigated through a numerous independent investigative procedures and the\n",
            "======================================== SAMPLE 8 ========================================\n",
            "\n",
            "\n",
            "what don't you want: horses in your face or extra dice on the Grand Chessboard\n",
            "\n",
            "\n",
            "All right! This is a very important guide that will help you, but it's not in any way god about football and using the game\n",
            "======================================== SAMPLE 9 ========================================\n",
            " \"Tortoise crossed the finish line and reached the knot of both Tetris boards.\" So do the rabbit and the bear walk, each one at its own pace, then pee. Where did all the other animals lead? Why, whenever possible,\n",
            "======================================== SAMPLE 10 ========================================\n",
            "\n",
            "All jokes aside, this all is a bit hard to relate to. What is it that happens when a non-human stretches and yawns all day, while a non-human closest to danger, gets pumped full of adrenaline and wants every second\n",
            "======================================== SAMPLE 11 ========================================\n",
            " Tortoise ran it's 15,000 mile run in one continuous stretch. 43 hours in total. \"So, George what if we're not being watched? Won't the Martians see us crawling through space again? :)\" \"We\n",
            "======================================== SAMPLE 12 ========================================\n",
            " My statement about the Frog and the Hare \n",
            "The Hare is a profound key of the human condition namely the situation in which perception simplifies to exclude objectivity. Not the Crab inside that Worm is the other key point of the human condition from which\n",
            "======================================== SAMPLE 13 ========================================\n",
            " the race for man and man's best friend, the Carcass, was ended by the late recovery of the Tortoise.\n",
            "\n",
            "Advertisements<|endoftext|>Tom Perez Sees 'Credibility Flipped' In Voice Vote On Transportation — Will He Continue\n",
            "======================================== SAMPLE 14 ========================================\n",
            " - \"Harmony.\"<|endoftext|>Thank you, Thomas! Enjoying some fellow redditors today??\n",
            "\n",
            "I have saved plans before. Anyways, after I went to breakfast along with Jennifer , General Manager here at Ryerson , said....\n",
            "======================================== SAMPLE 15 ========================================\n",
            " the shuttle cried sendsay and adieu, and the dead animal to be buried fresh some place, rich in its own right. 7 Addenda. Henny-Penny's condition was excellent. We left her soon after dusk and as promised set\n",
            "================================================================================\n",
            "Model prompt >>> his is the story of a young girl who was given an unusual task to coach her illiterate grandma, how to read. She was stunned at first with this request, but her experience in teaching and training her grandmother, gave her a different perspective on life. It changed her completely for better forever.  The grandmother of the little girl had a great pleasure in life and it was hearing the stories narrated by her granddaughter. The old woman regretted that she could not have formal education and read her favorite stories. So, she made a request to her granddaughter to educate her.  The story is plotted and narrated on different issues which are mostly overlooked in today’s world. For instance, how do you react for scoring more marks in the exam than you actually deserve; what would you do if you are discriminated?  The story captures many beautiful moments of life.  The book doesn’t tell you or make you oblige to what is right and what is wrong. Rather, it makes you take independent decisions based on the life experiences. The book is more than a story, as it carries a motivational facet.\n",
            "======================================== SAMPLE 1 ========================================\n",
            " The characters are experienced and both young and old. The narrator (A, was also my college classmate still playing cricket in college) greatly affected me when t will grab the audience with his story of his love. The story and the characters keep us secure\n",
            "======================================== SAMPLE 2 ========================================\n",
            " If you get faulty assessment from the teacher, then you need this book to recover the faith of starting with a strong system of learning. Has it even a point to try to be a doctor, an animal trainer or an accountant? No. But,\n",
            "======================================== SAMPLE 3 ========================================\n",
            " Learners can rest on the big picture of the book. The authors' mastery of line and writing together (90’) is nothing short of astonishing. A agonizing part shocking to boys64 years back is the fact that the author accurately\n",
            "======================================== SAMPLE 4 ========================================\n",
            " Let us see what happens next.\n",
            "\n",
            "The story has a summary/slide show (slideshare.se 〉) , giving glimpses/picture of various problems one encounters in the work and the solutions he/she comes up\n",
            "======================================== SAMPLE 5 ========================================\n",
            " Instead of condemning people for their capacity to learn’s best use: be unique , its preach a message of compassion!<|endoftext|>Rahim is the editor of Literal Translation's website and contributor to the 23/3/17 Literal Translation News\n",
            "======================================== SAMPLE 6 ========================================\n",
            "  Book check investment from:\n",
            "\n",
            "Amazon | Indie Bound | Audible<|endoftext|>Cancer and Reproductive Harm- Cancer and Reproductive Harm- www.P65Warnings.ca.gov\n",
            "\n",
            "Crosman XM-L powerful\n",
            "======================================== SAMPLE 7 ========================================\n",
            " A beautiful book to be adopted by everyone. In all its form it is a real life story. The voice of the grandma is also inspiring because she makes you understand why being independent is so important. It is pretty captivating j & you may just\n",
            "======================================== SAMPLE 8 ========================================\n",
            " The author describes as unreal what happened to her grandmother after trying her unorthodox skills. And that it will continue to haunt her for the rest of her life.  Dietysm record\n",
            "And here's the story: It was Moriya who had this\n",
            "======================================== SAMPLE 9 ========================================\n",
            "  Public Voice believes that we must do more to adopt, promote and support technology as a healing medium. By showing the cases of people with disabilities, dyslexia is offered as an inspiration and likelihood to croak-out. We can show more\n",
            "======================================== SAMPLE 10 ========================================\n",
            " Sophisticated and suspenseful, this book inspires introspection and helps the reader grapple with a true dilemma in today's world.\n",
            "Posted by ataaya at 6:23 PM<|endoftext|>(Truthstream Media.com)\n",
            "\n",
            "Photo by Zach\n",
            "======================================== SAMPLE 11 ========================================\n",
            " It express-sos a person is indiligently living life and is daring to live hand in hand with his/her grandmother. It tells you to overcome your fear and make the right decision everytime. This book is for obsessive adults,\n",
            "======================================== SAMPLE 12 ========================================\n",
            " When you are gonna try something, it rings loud and true but when you are due for major changes, you might not be ready even after 2nd attempt.  And the life lessons inside are powerful and sometimes cool. The little girl who used to\n",
            "======================================== SAMPLE 13 ========================================\n",
            " And this is exactly what makes this book such a great read.\n",
            "** This is a must read, or any unpublished story. Although it is not yet translated into helping vers as many as possible. But with every update, now even people across India\n",
            "======================================== SAMPLE 14 ========================================\n",
            "  It gives you the life experiences to follow up on unplanned thoughts and actions, so that you can be successful; in times of sorrow or out of fear. I would definitely recommend this book.<|endoftext|>Description\n",
            "\n",
            "Novak is a wallet that\n",
            "======================================== SAMPLE 15 ========================================\n",
            " It teaches $upport and commitment by introducing gaining respect and being loved and being seen.  And there is nothing wrong with that…except its standardisation.\n",
            "\n",
            "\n",
            "With \n",
            "\n",
            "you making certain decisions based on the story, you are shown\n",
            "================================================================================\n",
            "Model prompt >>> Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.6/contextlib.py\", line 99, in __exit__\n",
            "    self.gen.throw(type, value, traceback)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py\", line 5480, in get_controller\n",
            "    yield g\n",
            "  File \"src/interactive_conditional_samples.py\", line 73, in interact_model\n",
            "    raw_text = input(\"Model prompt >>> \")\n",
            "KeyboardInterrupt\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"src/interactive_conditional_samples.py\", line 91, in <module>\n",
            "    fire.Fire(interact_model)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/fire/core.py\", line 138, in Fire\n",
            "    component_trace = _Fire(component, args, parsed_flag_args, context, name)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/fire/core.py\", line 471, in _Fire\n",
            "    target=component.__name__)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/fire/core.py\", line 675, in _CallAndUpdateTrace\n",
            "    component = fn(*varargs, **kwargs)\n",
            "  File \"src/interactive_conditional_samples.py\", line 88, in interact_model\n",
            "    print(\"=\" * 80)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\", line 1633, in __exit__\n",
            "    close_thread.start()\n",
            "  File \"/usr/lib/python3.6/threading.py\", line 851, in start\n",
            "    self._started.wait()\n",
            "  File \"/usr/lib/python3.6/threading.py\", line 551, in wait\n",
            "    signaled = self._cond.wait(timeout)\n",
            "  File \"/usr/lib/python3.6/threading.py\", line 295, in wait\n",
            "    waiter.acquire()\n",
            "KeyboardInterrupt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mrGY1DKAUWHk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "f3e10212-72bd-4409-eb99-50bd1017810a"
      },
      "source": [
        "ls"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CONTRIBUTORS.md  Dockerfile.gpu     LICENSE        README.md\n",
            "DEVELOPERS.md    domains.txt        model_card.md  requirements.txt\n",
            "Dockerfile.cpu   download_model.py  \u001b[0m\u001b[01;34mmodels\u001b[0m/        \u001b[01;34msrc\u001b[0m/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LJNT3JNI3AYP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "55c5bf4e-2aed-46cb-e9fb-4eefed06addf"
      },
      "source": [
        "cd .."
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CQkGS85b3Dzv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ac52246f-aa18-4660-bb59-e8dbb8a6e540"
      },
      "source": [
        "ls"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[0m\u001b[01;34mgpt-2\u001b[0m/  \u001b[01;34msample_data\u001b[0m/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BTgzKvGi3P6l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}